# About-Me

This QA-style README reveals a bit about myself in a playful self-interview. I hope it elicits a smile from my dear reader(s). 

Some parts are intentionally self-ironic (I know my faults), others are a bit more serious and reflect things I believe or feel strongly about. Nevertheless, I wish to conclude on a positive note.

Enjoy!



## Motivation

**Q:** Why do you feel these QA need a dedicated repository?<br>
**A: I hope it earns more stars than repositories containing my code.**

**Q:** How does a physicist end up doing computer programming?<br>
**A: Everything is physics. Your question is pointless.**

**Q:** Why do you love software development so much? <br>
**A: I love to be in control. But only machines, cats and squirrels obey.**



## Programming & Languages

**Q:** What is the worst language you were ever compelled to learn?<br>
**A: I can't decide between Latin and SQL. (I accomplished neither)** 

**Q:** Do you understand Mathematics as a language of nature?<br>
**A: I see Mathematics as a misunderstood force of nature.**

**Q:** Would you agree that the essence of [functional programming](https://en.wikipedia.org/wiki/Functional_programming) is doing [recursion](https://en.wikipedia.org/wiki/Functional_programming#Recursion)?<br>
**A: No. The essence is stopping recursion.**

**Q:** Does the [Ackermann Function](https://en.wikipedia.org/wiki/Ackermann_function) fascinate you?<br>
**A: I'll be fascinated seeing A(4,3) finish.** 

**Q:** What is the most important (operator-) symbol in a functional language?<br>
**A: The semicolon!** 

**Q:** But that is used to complete a statement. Python even dropped it altogether. How can that be?<br>
**A: My point exactly.** 

**Q:** You seem to love developing your own language. Are you good at languages?<br>
**A: I've never learned any well. So, I keep inventing my own.** 

**Q:** Why [Xoila](https://github.com/johsteffens/beth?tab=readme-ov-file#xoila)? For a language, that name seems like a weird choice.<br>
**A: Xoila was the shortest name not claimed as trademark or company name. So, I've got very little competition in Google's ranking.** 

**Q:** Should the name not better reflect the use case?<br>
**A: Xoila is a tasty Nepalese dish made of meat with chilly, garlic and ginger. That describes it perfectly!** 

**Q:** Interesting. But don't you feel other languages carry more suitable names? <br>
**A: Well, a [popular language](https://en.wikipedia.org/wiki/Python_(programming_language)) is named after a predator that squeezes its prey to death, then swallows it whole. I'm undecided which use case is implied here. Don't get me wrong: I like that language but it doesn't give me nightmares ... (yet).** 

**Q:** Perhaps the name need not describe the purpose after all?<br>
**A: Perhaps.** 



## Beth

**Q:** Why did you choose the name ***[Beth](https://github.com/johsteffens/beth)***? <br>
**A: *Aleph* was taken.** 

**Q:** Other reasons? <br>
**A: It is an abbreviation for the second name of my beloved daughter.** 

**Q:** Any more? <br>
**A: Beth also means *second*, which I take as personal stance. I don't like to push myself into the foreground.** 

**Q:** Oh, it is a posture of humility then! An admission that you are not the best developer in the universe? <br>
**A: Correct!**  *<sub> ... maybe the second best ... </sub>*

**Q:** It seems you dislike third party code. How come?<br>
**A: I love third party code, except (by definition) one cannot own it. One must acquire a license; I'm allergic to that.**

**Q:** But you issue a license for your own code?<br>
**A: I'm immune to licenses issued by me.**

**Q:** Why did you select [Apache 2.0](https://github.com/johsteffens/beth/blob/master/LICENSE)?<br>
**A: It reminds me of stories written by Karl May, which I loved as a kid.**



## About Innovation

**Q:** What, in your opinion, is the most misunderstood idiom in software development?<br>
**A: *Not invented by me!***

**Q:** Looking through your code, it seems you love reinventing the wheel. What is your take on that?<br>
**A: I invented the wheel!**

**Q:** Well, lets agree that you have an inventive spirit. Can you elaborate?<br>
**A: I love solving problems or improving existing solutions. I also enjoy tackling already solved problems from a different viewpoint and eventually discover different (occasionally better) methods. I generally do not expect to be the first arriving at any particular solution. Though, that happens occasionally, too.**

**Q:** Where does that inclination come from?<br>
**A: It could be considered a learning disorder.**

**Q:** A disorder? Please elaborate.<br>
**A: I've difficulty learning and understanding simply by memorizing things. Instead I learn by reinventing/rediscovering and eventually comparing my result to the generally accepted one. That process can be quite slow and tedious. When my result agrees, I get a dopamine rush. When it disagrees, one of two cases apply.**

**Q:** Which two cases?<br>
**A:**

1. **I am mistaken.**
2. **Everyone else is mistaken!**   <sub> ... and I might be due for the next Nobel Price.</sub> 



## About Software Patents

**Q:** What is your position on software patents? <br>
**A: It carries signs of a bad religion.**

**Q:** That is an unexpected association. Please explain? <br>
**A: Software patents obfuscate with pointless jargon. It keeps the innocent in constant fear to infringe on things, which they themselves would rather consider trivial and obvious.**

**Q:** Oh dear, I sense irony slipping into ranting. Did I touch a soar nerve? <br>
**A: Well, kind of. Sorry.**

**Q:** Should innovation not be protected? <br>
**A: It should. There are legitimate inventors as well as benevolent investors (or employers) both are entitled to benefit from their effort/investment. But there are also thieves in the world. The two former need protection from the latter. That is desirable as well as justified. And it was even the original spirit for introducing patents in general.**

**Q:** What then went wrong? <br>
**A: Some misuse cannot be sufficiently prevented: Such as patenting the 'obvious', unduly broad claims and ignoring prior art (intentionally or unintentionally). I'd say we don't even have a good understanding what 'obvious' truly means.**

**Q:** How then would you personally define 'obvious'? <br>
**A: A specific solution one inevitably arrives at when one put his/her mind to solving a particular problem. Regardless how difficult that solution might be to find.**

**Q:** Does this not apply to all possible solutions? <br>
**A: No. Many solutions contain some level of design which leaves room for developing alternatives. A good patent should only claim the one original design. It should not be so broad that it potentially covers all possible future alternatives, which haven't been invented yet.**

**Q:** I can see that your tight definition might render some of today's patents invalid. What is your better solution to patenting? <br>
**A: I have none (yet). At best I have a preliminary remedy but it might not work for everyone.**

**Q:** What is your remedy? <br>
**A: Publish everything you develop under your name; but don't patent it. If you want to do extra good, issue a permissive license with it. By publishing, you turn your invention into prior art. You have a defense gainst those, who claim your idears afterwards as their own. No one should be able to patent your invention without your permission. (At least not in jurisdictions that deserve my respect.) At the same time you leave room to breathe to those, who value your approach and want to adapt, integrate or improve on it.**

**Q:** Why might that not work out for everyone? <br>
**A: Hard work deserves remuneration. Many inventors need guarantees that they can turn teir efforts into profit. Publishing without patenting is rather a leap of faith. You do something good and hope that you'll be rewarded somehow but also accept that it might never happen. At least not in the way you expect, deserve or need. Many cannot afford living up to this principle, although they might agree that it is a valiant one.**

**Q:** Some countries allow software patents. Should they better abolish it? <br>
**A: No. There are legitimate claims depending on the existing systems remaining in place. The system needs a change, but it must be a gradual one.**

**Q:** Some countries withstand industrial pressure to allow software patents. Should they relent? <br>
**A: Emphatically no! Pressure is healthy when it is channeled into efforts for better solutions. I maintain hope that arrive at a good one, eventually.**

**Q:** From where do you think might a better solution arise. <br>
**A: The free software movement has brought up many excellent ideas. The missing step is finding a grand unified theory combining freedom and protection.**

**Q:** So, you associate the effort with the quest for the [GUT](https://en.wikipedia.org/wiki/Grand_Unified_Theory) in physics? <br>
**A: Yes. Btw.: *Everything is physics!***

**Q:** Is it also equally difficult? <br>
**A: I'm optimistic for both.**



## About AI

**Q:** What is a [Holor Virtual Machine](https://github.com/johsteffens/beth/blob/master/lib/bhvm/README.md)? <br>
**A: A virtual platform I ivented. It can run holor (e.g. scalar, vector, matrix, ...)  operations. Especially useful for artificial neural networks.**

**Q:** What means [bhpt](https://github.com/johsteffens/beth/tree/master/lib/bhpt)? <br>
**A: A (yet) incomplete framework to design and train neural networks.**

**Q:** You started developing these exciting tools but seem to have halted midway. What happened? <br>
**A: The AI-Hype happened.**

**Q:** OK, some experts agree, that today's talk around AI is indeed rather a hype. But why should that inhibit you? <br>
**A: Expectations are inflated. I couldn't possible meet them.**

**Q:** Since when do you care what others expect? And why should any hype affect your motivation? <br>
**A: I thought I'd be solely self-motivated and never care what others think. In truth, I probably care a lot. I'm motivated building something, which others might find helpful. My work on neural networks might simply appear boring at the moment.**

**Q:** In which way do you think common expectation around AI is inflated? <br>
**A: Among others: AI is perceived to generate new uncorrelated information.**

**Q:** I thought people fear that AI is skidding into some form of runaway intelligence turning into an [AGI](https://en.wikipedia.org/wiki/Artificial_general_intelligence) with unpredictable, possibly harmful, outcome.<br>
**A: That is basically the same thing! And it is not happening.**

**Q:** Why is it the same and how is it not happening?<br>
**A: Let first strip science fiction, romanticism and trivialities from AI: What remains is professionally known as 'Machine Learning'. I consider even that a misnomer. But for lack of a better term, I'll stick with it.**

**Q:** OK, we actually talk about "Machine Learning". Proceed.<br>
**A: Without getting too technical, Machine Learning is the symbiosis of algorithm, data and computational power, in order to discover structure in data and using it for decisions. That structure need never be revealed to or even understood by a human. It is sufficient that an algorithm can use it to perform decisions.**

**Q:** Sounds like a reasonable top level definition. What next?<br>
**A: That structure is a form of filtered information originating from the training data. When it is used to make decisions, it can not create new structure. It only applies structure obtained from the training data. Although that sounds restrictive, one can accomplish quite marvelous things with it. But it is a limiting condition. I've not seen anything, called AI, ever working outside these boundaries.**

**Q:** One objection: How about [GAN](https://en.wikipedia.org/wiki/Generative_adversarial_network)? It seems to create new data out of nothing. That data looks like information no one has seen before. Is that not also new structure? <br>
**A: You seem to refer to the ability of art-creation by Generative Adversarial Networks. It creates indeed new data but not new structure. It learned to model the space of potential art and to maximize distance to actual (human created) art. That is the intrinsic structure used by the system. The rest is simply mapping a random vector into an arbitrary point that space of maximal distance. So, generating an artificial piece of art is simply mapping a random vector. No new structure is created here!**

**Q:** Well, putting it like that seems to take some magic out of the GAN. But is it not still quite intriguing what these networks can do?<br>
**A: Yes, it is a brilliant concept. In a very specific field it is able to produce quite impressive results. Nevertheless, the GAN is a specialized machinery and no a pathway to general intelligence.**

**Q:** Another objection: A [LLM](https://en.wikipedia.org/wiki/Large_language_model) can create code. So, code and data does not seem to have a distinct boundary. Since the LLM itself is code, could it not teach itself to better itself and thus become a runaway intelligence?<br>
**A: No, it can't! The LLM is very good in doing associations. LLMs can extract meaning of presented data and output associated data, which falls into a specific range of human-expectation. Hence, these machines exhibit human-like behavior. However, any output is driven by structure, which already was part of the training data. Thus, it is unable to give you a solution to - say - the Collaz Conjecture, the Rieman Hypothesis or the P versus NP problem unless unless a true intelligence has solved and published it beforehand. In the same way it can't better itself unless a true intelligence has already published a better LLM.**

**Q:** So, what is missing? <br>
**A: The ability to generate (meaningful) structure out of nothing. If that was possible, structure could be used in a self-replicating manner, resulting in a exponential growth (or explosion). That could produce a runaway intelligence.**

**Q:** Might that not be possible? <br>
**A: Structure appears to be a tangible quantity as well as a conserved one, like physical energy is conserved. You can filter certain types of structure from data much like you can extract energy from natural resources. You can probably convert structure (though we don't have a good definition what that exactly means), like you can convert energy. But you can't create it from nothing.**

**Q:** Physics again? <br>
**A: Did I mention that everything is ...**

**Q:** ... Yes! So, your point is that we need not be afraid fear for the emergence of a malicious runaway artificial intelligence?<br>
**A: Correct.**

**Q:** But how about being cautious and possibly applying regulatory efforts on AI? Should we rather let up? <br>
**A: Machine learning, like any technology, can be abused by humans. Caution, just like we are cautious with any form of technology, is a good thing. Where significant abuse is observed or highly probable, proper regulation is needed. If self-regulation is insufficient, legislation must step in. However, there is no basis for a prohibitive or excessive-regulatory stance simply out of vague fears about the unknown. Sometimes it seems to me that such fears are actively kindled for the purpose to influence legislation with respect to AI.**



## Perpetual Generative Intelligence

**Q:** Isn't AI also part of biophysics? <br>
**A: The field of neural networks is part of neuroscience which is part of biophysics. The term AI is a bit warped these days.**

**Q:** Does that mean artificial neural networks were originally developed by physicists? <br>
**A: By psychologists, mathematicians and computer scientists (Rosenblatt, Werbos, Rummelhard, Hinton, Williams, Malsburg, ...) who worked widely interdisciplinary. Of these, only professor v.d. Malsburg is a physicist.**

**Q:** Why is it called *Biophysics* then? <br>
**A: Biophysics is rather an umbrella term for interdisciplinary science around many areas in biology accessible using physical principles. Did I mention that *everything is Physics*?**

**Q:** I vaguely recall you mentioning something of the kind. So, what is going to happen, oh omniscient physicist: Will we one day eventually all be consumed by intelligent machines? Will AI teach us how to become better humans? Or will AI come to believe that it already is the better human?<br>
**A: Are you mocking me? If AI ever accomplishes anything useful, it will teach you manners!**

**Q:** It seems we are coming back to the one question: Can you formulate what part, piece or concept is missing? <br>
**A: From making the worst nightmares come true? I'd call the missing part a "Perpetual Generative Intelligence". A system that can learn from its own output. It seems impossible for all the reasons stated already.**

**Q:** But is the the human brain not just such a machine? Thus disproving your statement? <br>
**A: I wouldn't claim this for any individual. Humankind as a whole appears to exhibit traits of it to a limited degree. We don't see an intelligence explosion among humans because each new human has to learn everything from scratch (more or less).**

**Q:** So, we can all rest in peace? <br>
**A: Your dictum reminds me of a funeral. I'd rather say: "We can relax a bit!". There is time to soberly observe and objectively think it out. There is no need for fear or panic.**





&copy; Johannes B. Steffens

The content in this document is licensed under: [CC BY-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0)
